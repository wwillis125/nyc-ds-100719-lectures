{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engines: Content-based and Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based\n",
    "\n",
    "We will first build a content-based model using our movies from the classification problem, to find which movies are similiar to other movies based solely on the plot summary of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_English_1960.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Title', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6706, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>2012</td>\n",
       "      <td>The Most Fun You Can Have Dying</td>\n",
       "      <td>British</td>\n",
       "      <td>Kirstin Marcon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Most_Fun_You...</td>\n",
       "      <td>The story begins in Hamilton, New Zealands fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>2012</td>\n",
       "      <td>Riot on Redchurch Street</td>\n",
       "      <td>British</td>\n",
       "      <td>Trevor Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>crime</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Riot_on_Redchurc...</td>\n",
       "      <td>Set in the hipster-underworld of Shoreditch, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>2013</td>\n",
       "      <td>Learning Hebrew</td>\n",
       "      <td>British</td>\n",
       "      <td>Louis Joon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Learning_Hebrew</td>\n",
       "      <td>The plot notes on the UK version DVD sleeve read:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>2013</td>\n",
       "      <td>The Zombie King</td>\n",
       "      <td>British</td>\n",
       "      <td>Aidan Belizaire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Zombie_King</td>\n",
       "      <td>Samuel Peters (Edward Furlong), once an ordina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>2014</td>\n",
       "      <td>Highway to Dhampus</td>\n",
       "      <td>British</td>\n",
       "      <td>Rick McFarland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Highway_to_Dhampus</td>\n",
       "      <td>Film Tagline:\\r\\nWe look at the sky, but we wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>2014</td>\n",
       "      <td>Lost in Karastan</td>\n",
       "      <td>British</td>\n",
       "      <td>Ben Hopkins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lost_in_Karastan</td>\n",
       "      <td>Lost in Karastan[2] is a gentle black comedy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>2014</td>\n",
       "      <td>One by One</td>\n",
       "      <td>British</td>\n",
       "      <td>Diane Jessie Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/One_by_One_(2013...</td>\n",
       "      <td>A cafe worker is violently jolted from her day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>2014</td>\n",
       "      <td>The President</td>\n",
       "      <td>British</td>\n",
       "      <td>Mohsen Makhmalbaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_President_(2...</td>\n",
       "      <td>A revolution is happening in a country with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>2014</td>\n",
       "      <td>We Still Kill the Old Way (2014 film)</td>\n",
       "      <td>British</td>\n",
       "      <td>Sacha Bennett</td>\n",
       "      <td>NaN</td>\n",
       "      <td>action</td>\n",
       "      <td>https://en.wikipedia.org/wiki/We_Still_Kill_th...</td>\n",
       "      <td>A retired East End gangster, Ritchie Archer, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>2014</td>\n",
       "      <td>What Goes Up</td>\n",
       "      <td>British</td>\n",
       "      <td>Matt Gambell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/What_Goes_Up</td>\n",
       "      <td>Upon arriving in Concord, New Hampshire in Jan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Release Year                                  Title Origin/Ethnicity  \\\n",
       "6696          2012        The Most Fun You Can Have Dying          British   \n",
       "6697          2012               Riot on Redchurch Street          British   \n",
       "6698          2013                        Learning Hebrew          British   \n",
       "6699          2013                        The Zombie King          British   \n",
       "6700          2014                     Highway to Dhampus          British   \n",
       "6701          2014                       Lost in Karastan          British   \n",
       "6702          2014                             One by One          British   \n",
       "6703          2014                          The President          British   \n",
       "6704          2014  We Still Kill the Old Way (2014 film)          British   \n",
       "6705          2014                           What Goes Up          British   \n",
       "\n",
       "                 Director Cast   Genre  \\\n",
       "6696       Kirstin Marcon  NaN   drama   \n",
       "6697        Trevor Miller  NaN   crime   \n",
       "6698           Louis Joon  NaN   drama   \n",
       "6699      Aidan Belizaire  NaN  comedy   \n",
       "6700       Rick McFarland  NaN   drama   \n",
       "6701          Ben Hopkins  NaN  comedy   \n",
       "6702  Diane Jessie Miller  NaN   drama   \n",
       "6703    Mohsen Makhmalbaf  NaN   drama   \n",
       "6704        Sacha Bennett  NaN  action   \n",
       "6705         Matt Gambell  NaN  comedy   \n",
       "\n",
       "                                              Wiki Page  \\\n",
       "6696  https://en.wikipedia.org/wiki/The_Most_Fun_You...   \n",
       "6697  https://en.wikipedia.org/wiki/Riot_on_Redchurc...   \n",
       "6698      https://en.wikipedia.org/wiki/Learning_Hebrew   \n",
       "6699      https://en.wikipedia.org/wiki/The_Zombie_King   \n",
       "6700   https://en.wikipedia.org/wiki/Highway_to_Dhampus   \n",
       "6701     https://en.wikipedia.org/wiki/Lost_in_Karastan   \n",
       "6702  https://en.wikipedia.org/wiki/One_by_One_(2013...   \n",
       "6703  https://en.wikipedia.org/wiki/The_President_(2...   \n",
       "6704  https://en.wikipedia.org/wiki/We_Still_Kill_th...   \n",
       "6705         https://en.wikipedia.org/wiki/What_Goes_Up   \n",
       "\n",
       "                                                   Plot  \n",
       "6696  The story begins in Hamilton, New Zealands fou...  \n",
       "6697  Set in the hipster-underworld of Shoreditch, E...  \n",
       "6698  The plot notes on the UK version DVD sleeve read:  \n",
       "6699  Samuel Peters (Edward Furlong), once an ordina...  \n",
       "6700  Film Tagline:\\r\\nWe look at the sky, but we wa...  \n",
       "6701  Lost in Karastan[2] is a gentle black comedy a...  \n",
       "6702  A cafe worker is violently jolted from her day...  \n",
       "6703  A revolution is happening in a country with a ...  \n",
       "6704  A retired East End gangster, Ritchie Archer, r...  \n",
       "6705  Upon arriving in Concord, New Hampshire in Jan...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drama        2202\n",
       "comedy       2144\n",
       "horror        777\n",
       "thriller      512\n",
       "action        472\n",
       "western       193\n",
       "adventure     174\n",
       "crime         125\n",
       "romance       107\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(text):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = nlp(text)\n",
    "    \n",
    "#     mytokens = [word for word in mytokens if word.pos_ != \"PROPN\"]\n",
    "    \n",
    "    mytokens = [ word if word.pos_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6706, 15305)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(tokenizer=spacy_tokenizer, min_df=5, max_df=.7)\n",
    "\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df['Plot'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this matrix in hand, you can now compute a similarity score. There are several candidates for this; such as the euclidean, the Pearson and the cosine similarity scores. Again, there is no right answer to which score is the best. Different scores work well in different scenarios and it is often a good idea to experiment with different metrics.\n",
    "\n",
    "You will be using the cosine similarity to calculate a numeric quantity that denotes the similarity between two movies. You use the cosine similarity score since it is independent of magnitude and is relatively easy and fast to calculate (especially when used in conjunction with TF-IDF scores, which will be explained later). Mathematically, it is defined as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/2815/1*6HISTi8SjbD2VHicoZwKpA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have used the TF-IDF vectorizer, calculating the dot product will directly give you the cosine similarity score. Therefore, you will use sklearn's linear_kernel() instead of cosine_similarities() since it is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to define a function that takes in a movie title as an input and outputs a list of the 10 most similar movies. Firstly, for this, you need a reverse mapping of movie titles and DataFrame indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df.index, index=df['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now in a good position to define your recommendation function. These are the following steps you'll follow:\n",
    "\n",
    "- Get the index of the movie given its title.\n",
    "- Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position and the second is the similarity score.\n",
    "- Sort the aforementioned list of tuples based on the similarity scores; that is, the second element.\n",
    "- Get the top 10 elements of this list. Ignore the first element as it refers to self (the movie most similar to a particular movie is the movie itself).\n",
    "- Return the titles corresponding to the indices of the top elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df['Title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331           Grown Ups 2\n",
       "3128      Mighty Aphrodite\n",
       "835     The Heartbreak Kid\n",
       "3645    Lulu on the Bridge\n",
       "5065             Grown Ups\n",
       "2069             The Boost\n",
       "1187        Paradise Alley\n",
       "6639            Incendiary\n",
       "4067             Rock Star\n",
       "3440           Eve's Bayou\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Infidel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "Above we were using a content-based approach, which requires a good amount of information of items’ own features. Collaborative Filtering, on the other hand, doesn’t need anything else except users’ historical preference on a set of items. Because it’s based on historical data, the core assumption here is that the users who have agreed in the past tend to also agree in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Based\n",
    "The first category includes algorithms that are memory based, in which statistical techniques are applied to the entire dataset to calculate the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighborhood\n",
    "The standard method of Collaborative Filtering is known as Nearest Neighborhood algorithm. There are user-based CF and item-based CF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-based CF\n",
    "![alt text](https://miro.medium.com/max/1813/1*mM089Lta5X6zkUkULcO9aA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item-based CF\n",
    "![alt text](https://miro.medium.com/max/2048/1*dPzd5-dScFplypBGeSwgUw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build an item-based collaborative filtering model to predict movie ratings for different users.  We have an n × m matrix of ratings, with user uᵢ, i = 1, ...n and item pⱼ, j=1, …m. Now we want to predict the rating rᵢⱼ if target user i did not watch/rate an item j. \n",
    "![alt text](https://files.realpython.com/media/rating-matrix.04153775e4c1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps Involved in Collaborative Filtering:\n",
    "\n",
    "- How do you determine which users or items are similar to one another?\n",
    "- Given that you know which users are similar, how do you determine the rating that a user would give to an item based on the ratings of similar users?\n",
    "- How do you measure the accuracy of the ratings you calculate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/2395/1*mTRUakSIWmo9OX6D2HakWQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While different people may have different baselines when giving ratings, some people tend to give high scores generally, some are pretty strict even though they are satisfied with items. To avoid this bias, we can subtract each user’s average rating of all items when computing weighted average, and add it back for target user, shown as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/2505/1*gLbwJts3g_v2TbPRhFoNfA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two ways to calculate similarity are **Pearson Correlation** and **Cosine Similarity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/3140/1*Xvf2o6kE4VCuueMPikxZ_A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/2815/1*6HISTi8SjbD2VHicoZwKpA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few limitations of this method. It doesn’t handle sparsity well when no one in the neighborhood rated an item that is what you are trying to predict for target user. Also, it’s not computational efficient as the growth of the number of users and products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /anaconda3/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.16.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# This is the same data that was plotted for similarity earlier\n",
    "# with one new user \"E\" who has rated only movie 1\n",
    "ratings_dict = {\n",
    "    \"item\": [1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    \"user\": ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E'],\n",
    "    \"rating\": [1, 2, 2, 4, 2.5, 4, 4.5, 5, 3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Loads Pandas dataframe\n",
    "data = Dataset.load_from_df(df[[\"user\", \"item\", \"rating\"]], reader)\n",
    "# Loads the builtin Movielens-100k data\n",
    "movielens = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "# To use item-based cosine similarity\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(k= 20, min_k=5, sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x13dbd43c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet = data.build_full_trainset()\n",
    "\n",
    "algo.fit(trainingSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = algo.predict('E', 2)\n",
    "prediction.est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Algorithm Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True],\n",
    "}\n",
    "\n",
    "\n",
    "param_grid = {\"k\":[10,20,30,40],\n",
    "            \"sim_options\": sim_options}\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based\n",
    "The second category covers the Model based approaches, which involve a step to reduce or compress the large but sparse user-item matrix.\n",
    "\n",
    "**Matrix factorization** can be seen as breaking down a large matrix into a product of smaller ones. This is similar to the factorization of integers, where 12 can be written as 6 x 2 or 4 x 3. In the case of matrices, a matrix A with dimensions m x n can be reduced to a product of two matrices X and Y with dimensions m x p and p x n respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithms for Matrix Factorization\n",
    "One of the popular algorithms to factorize a matrix is the singular value decomposition (SVD) algorithm. SVD came into the limelight when matrix factorization was seen performing well in the Netflix prize competition. Other algorithms include PCA and its variations, NMF, and so on. Autoencoders can also be used for dimensionality reduction in case you want to use Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
